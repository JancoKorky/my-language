// Generated automatically by nearley, version 2.20.1
// http://github.com/Hardmath123/nearley
(function () {
function id(x) { return x[0]; }

const myLexer = require ("./lexer");
var grammar = {
    Lexer: myLexer,
    ParserRules: [
    {"name": "statements$ebnf$1", "symbols": []},
    {"name": "statements$ebnf$1$subexpression$1", "symbols": ["__lb", "statement", "_"]},
    {"name": "statements$ebnf$1", "symbols": ["statements$ebnf$1", "statements$ebnf$1$subexpression$1"], "postprocess": function arrpush(d) {return d[0].concat([d[1]]);}},
    {"name": "statements", "symbols": ["_ml", "statement", "statements$ebnf$1", "_ml"], "postprocess": 
        (data) => {
            const repeated = data[2];
            const restStat = repeated.map(stat => stat[1])
            return [data[1], ...restStat]
        }
                },
    {"name": "statement", "symbols": ["variable_assign"], "postprocess": id},
    {"name": "statement", "symbols": ["fun_call"], "postprocess": id},
    {"name": "statement", "symbols": [(myLexer.has("comment") ? {type: "comment"} : comment)], "postprocess": id},
    {"name": "fun_call$ebnf$1$subexpression$1", "symbols": ["arg_list", "_ml"]},
    {"name": "fun_call$ebnf$1", "symbols": ["fun_call$ebnf$1$subexpression$1"], "postprocess": id},
    {"name": "fun_call$ebnf$1", "symbols": [], "postprocess": function(d) {return null;}},
    {"name": "fun_call", "symbols": [(myLexer.has("identifier") ? {type: "identifier"} : identifier), (myLexer.has("lpar") ? {type: "lpar"} : lpar), "_ml", "fun_call$ebnf$1", (myLexer.has("rpar") ? {type: "rpar"} : rpar)], "postprocess": 
        (data) => {
            return{
                type: "fun_call",
                fun_name: data[0],
                arguments: data[3] ? data[3][0]: []
            }
        }
                },
    {"name": "variable_assign", "symbols": [(myLexer.has("keyword") ? {type: "keyword"} : keyword), "__", (myLexer.has("identifier") ? {type: "identifier"} : identifier), "_", {"literal":"="}, "_", "expression"], "postprocess": 
        (data) => {
            return {
                type: "var_assign",
                var_type: data[0],
                var_name: data[2],
                value: data[6],
            }
        }
                },
    {"name": "arg_list", "symbols": ["expression"], "postprocess": 
        (data) => {
            return [data[0]]
        }
                },
    {"name": "arg_list", "symbols": ["arg_list", "_ml", (myLexer.has("comma") ? {type: "comma"} : comma), "_ml", "expression"], "postprocess": 
        (data) => {
            return [...data[0], data[4]]
        }
                },
    {"name": "lambda$ebnf$1$subexpression$1", "symbols": ["param_list", "_"]},
    {"name": "lambda$ebnf$1", "symbols": ["lambda$ebnf$1$subexpression$1"], "postprocess": id},
    {"name": "lambda$ebnf$1", "symbols": [], "postprocess": function(d) {return null;}},
    {"name": "lambda", "symbols": [(myLexer.has("lpar") ? {type: "lpar"} : lpar), "_", "lambda$ebnf$1", (myLexer.has("rpar") ? {type: "rpar"} : rpar), "_", (myLexer.has("fatarrow") ? {type: "fatarrow"} : fatarrow), "_ml", "lambda_body"], "postprocess": 
        (data) => {
            return {
                type: "lambda",
                parameters: data[2] ? data[2][0] : [],
                body: data[7]
            }
        }
            },
    {"name": "param_list$ebnf$1", "symbols": []},
    {"name": "param_list$ebnf$1$subexpression$1", "symbols": ["_", (myLexer.has("comma") ? {type: "comma"} : comma), "_", (myLexer.has("identifier") ? {type: "identifier"} : identifier)]},
    {"name": "param_list$ebnf$1", "symbols": ["param_list$ebnf$1", "param_list$ebnf$1$subexpression$1"], "postprocess": function arrpush(d) {return d[0].concat([d[1]]);}},
    {"name": "param_list", "symbols": [(myLexer.has("identifier") ? {type: "identifier"} : identifier), "param_list$ebnf$1"], "postprocess": 
        (data) => {
            const repeatedIdentifier = data[1];
            const restParams = repeatedIdentifier.map(identf => identf[3]);
            return [data[0], ...restParams];
        }
                },
    {"name": "lambda_body", "symbols": [(myLexer.has("lcurly") ? {type: "lcurly"} : lcurly), "statements", (myLexer.has("rcurly") ? {type: "rcurly"} : rcurly)], "postprocess": 
        (data) => {
            return data[1];
        }
                },
    {"name": "lambda_body", "symbols": ["expression"], "postprocess": 
        (data) => {
            return [data[0]];
        }
                },
    {"name": "expression", "symbols": [(myLexer.has("string") ? {type: "string"} : string)], "postprocess": id},
    {"name": "expression", "symbols": [(myLexer.has("integer") ? {type: "integer"} : integer)], "postprocess": id},
    {"name": "expression", "symbols": [(myLexer.has("identifier") ? {type: "identifier"} : identifier)], "postprocess": id},
    {"name": "expression", "symbols": ["fun_call"], "postprocess": id},
    {"name": "expression", "symbols": ["lambda"], "postprocess": id},
    {"name": "__lb$ebnf$1$subexpression$1", "symbols": ["_", (myLexer.has("newline") ? {type: "newline"} : newline)]},
    {"name": "__lb$ebnf$1", "symbols": ["__lb$ebnf$1$subexpression$1"]},
    {"name": "__lb$ebnf$1$subexpression$2", "symbols": ["_", (myLexer.has("newline") ? {type: "newline"} : newline)]},
    {"name": "__lb$ebnf$1", "symbols": ["__lb$ebnf$1", "__lb$ebnf$1$subexpression$2"], "postprocess": function arrpush(d) {return d[0].concat([d[1]]);}},
    {"name": "__lb", "symbols": ["__lb$ebnf$1", "_"]},
    {"name": "_ml$ebnf$1", "symbols": []},
    {"name": "_ml$ebnf$1$subexpression$1", "symbols": [(myLexer.has("whitespace") ? {type: "whitespace"} : whitespace)]},
    {"name": "_ml$ebnf$1$subexpression$1", "symbols": [(myLexer.has("newline") ? {type: "newline"} : newline)]},
    {"name": "_ml$ebnf$1", "symbols": ["_ml$ebnf$1", "_ml$ebnf$1$subexpression$1"], "postprocess": function arrpush(d) {return d[0].concat([d[1]]);}},
    {"name": "_ml", "symbols": ["_ml$ebnf$1"]},
    {"name": "__ml$ebnf$1$subexpression$1", "symbols": [(myLexer.has("whitespace") ? {type: "whitespace"} : whitespace)]},
    {"name": "__ml$ebnf$1$subexpression$1", "symbols": [(myLexer.has("newline") ? {type: "newline"} : newline)]},
    {"name": "__ml$ebnf$1", "symbols": ["__ml$ebnf$1$subexpression$1"]},
    {"name": "__ml$ebnf$1$subexpression$2", "symbols": [(myLexer.has("whitespace") ? {type: "whitespace"} : whitespace)]},
    {"name": "__ml$ebnf$1$subexpression$2", "symbols": [(myLexer.has("newline") ? {type: "newline"} : newline)]},
    {"name": "__ml$ebnf$1", "symbols": ["__ml$ebnf$1", "__ml$ebnf$1$subexpression$2"], "postprocess": function arrpush(d) {return d[0].concat([d[1]]);}},
    {"name": "__ml", "symbols": ["__ml$ebnf$1"]},
    {"name": "_$ebnf$1", "symbols": []},
    {"name": "_$ebnf$1", "symbols": ["_$ebnf$1", (myLexer.has("whitespace") ? {type: "whitespace"} : whitespace)], "postprocess": function arrpush(d) {return d[0].concat([d[1]]);}},
    {"name": "_", "symbols": ["_$ebnf$1"]},
    {"name": "__$ebnf$1", "symbols": [(myLexer.has("whitespace") ? {type: "whitespace"} : whitespace)]},
    {"name": "__$ebnf$1", "symbols": ["__$ebnf$1", (myLexer.has("whitespace") ? {type: "whitespace"} : whitespace)], "postprocess": function arrpush(d) {return d[0].concat([d[1]]);}},
    {"name": "__", "symbols": ["__$ebnf$1"]}
]
  , ParserStart: "statements"
}
if (typeof module !== 'undefined'&& typeof module.exports !== 'undefined') {
   module.exports = grammar;
} else {
   window.grammar = grammar;
}
})();
